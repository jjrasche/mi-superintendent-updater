# LLM Provider: 'groq' or 'ollama'
LLM_PROVIDER=groq

# Groq Configuration
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.3-70b-versatile
GROQ_TEMPERATURE=0.3

# Ollama Configuration
OLLAMA_URL=http://privatechat.setseg.org:11434/api/generate
OLLAMA_MODEL=gpt-oss:120b
OLLAMA_TEMPERATURE=0.3

# SSH Tunnel Configuration (for remote LLM servers)
# Set SSH_TUNNEL_ENABLED=true to connect to remote server via SSH
SSH_TUNNEL_ENABLED=false
SSH_HOST=jrasche-ai
SSH_REMOTE_PORT=8000
SSH_LOCAL_PORT=8000
# Optional: Leave blank to use ~/.ssh/config settings
SSH_USERNAME=
SSH_KEY_PATH=

# Database
DATABASE_URL=sqlite:///district_fetch.db
